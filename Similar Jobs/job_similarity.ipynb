{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c623c6b-fe6f-4af7-8241-9b3f17899c56",
   "metadata": {},
   "source": [
    "## Part A: Data Preprocessing, Model Training, and Storing the Model as a Pickle File\n",
    "\n",
    "### Data Preprocessing: \n",
    "Preprocess the text columns (title, description, skills_desc) in the dataset.\n",
    "### TF-IDF Vectorization: \n",
    "Perform TF-IDF vectorization on the preprocessed text data.\n",
    "### Cosine Similarity Calculation: \n",
    "Store the cosine similarity matrix as a h5py file, so it can be used later for making recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f303f8-42f5-4188-b8c4-203578d17075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37f5afc-1cb1-4667-bfb1-7db2a97bee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e859c65-2f52-4454-b5b1-10f020bb19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable for TF-IDF Vectorizer and Cosine Similarity Matrix\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=10000)  # Limit the number of features\n",
    "cosine_sim_matrix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22be663c-f75d-4c71-9a26-fbeee233ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936adcc8-15f8-409a-a416-8c3d5c940162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters and lowercase the text\n",
    "    text = re.sub(r'\\W', ' ', text.lower())\n",
    "    # Tokenize and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2658172e-39fb-43e2-b79d-83e203c649f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_model(data_path= 'C:/Users/DELL/Linkedin-Job-Market-Analysis-using-ML/LinkedIn Scraper/job postings 2023 24/postings.csv' ):\n",
    "    # Load job postings data\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # Combine the relevant text columns into a single string for each job\n",
    "    data[\"combined_text\"] = data[\"title\"].fillna('') + ' ' + data[\"description\"].fillna('') + ' ' + data[\"skills_desc\"].fillna('')\n",
    "    data[\"combined_text\"] = data[\"combined_text\"].apply(preprocess_text)\n",
    "    \n",
    "    # Perform TF-IDF vectorization\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"combined_text\"])\n",
    "    \n",
    "    # Use Approximate Nearest Neighbors with cosine similarity metric\n",
    "    nbrs = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='brute').fit(tfidf_matrix)\n",
    "\n",
    "    # Save the model and TF-IDF vectorizer to an HDF5 file\n",
    "    model_directory = \"D:/ARJYAHI/Models\"\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    h5_file_path = os.path.join(model_directory, 'model_data.h5')\n",
    "    \n",
    "    with h5py.File(h5_file_path, 'w') as h5f:\n",
    "        # Serialize the TF-IDF vectorizer with pickle and store in HDF5\n",
    "        tfidf_vectorizer_pickle = pickle.dumps(tfidf_vectorizer)\n",
    "        h5f.create_dataset('tfidf_vectorizer', data=np.void(tfidf_vectorizer_pickle))\n",
    "        # Save the NearestNeighbors model directly (or save parameters if large)\n",
    "        nbrs_pickle = pickle.dumps(nbrs)\n",
    "        h5f.create_dataset('nbrs', data=np.void(nbrs_pickle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d42a9928-c333-4166-8478-e425ea62bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_store_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488c446-5e0b-4c6a-bb67-fd27b2cb4576",
   "metadata": {},
   "source": [
    "## Part B: Loading the Files and Using the Model for Recommendations\n",
    "In Part B, we load the files and use them to make recommendations based on user input.\n",
    "\n",
    "This code is designed to recommend similar job postings based on a user's input, either a job title, a list of skills, or both. It uses a pre-trained machine learning model and cosine similarity to find the most relevant job postings. Here's how it works:\n",
    "\n",
    "1. **Preprocessing the Input**:\n",
    "The input text (either a job title, skills, or both) is preprocessed by removing non-alphanumeric characters and converting it to lowercase.\n",
    "The text is tokenized (split into individual words) and lemmatized (reduced to their base form) to standardize the words for comparison.\n",
    "Stop words (common but uninformative words like \"the\", \"is\", etc.) are removed during preprocessing.\n",
    "2. **Loading the Pre-trained Model**:\n",
    "The code loads a pre-trained TF-IDF vectorizer and Nearest Neighbors model from an HDF5 file using the h5py library. These models are used to vectorize the text input and find the most similar jobs based on the vectors.\n",
    "3. **Calculating Similarity**:\n",
    "The TF-IDF vectorizer transforms the preprocessed input into a numerical vector representation, which is then compared to vectors of job descriptions in the dataset.\n",
    "The Nearest Neighbors model calculates the cosine distances between the input text and the job descriptions.\n",
    "Cosine similarity is used as the metric for measuring similarity between the input and each job. Cosine similarity measures how close two vectors are in angle, and it ranges from 0 (no similarity) to 1 (perfect similarity). A lower cosine distance corresponds to higher similarity.\n",
    "4. **Calculating and Displaying Similarity Scores**:\n",
    "The distances returned by the Nearest Neighbors model are the dissimilarity values (i.e., the cosine distance). These values are converted to similarity scores by subtracting the distance from 1, since higher cosine similarity means the jobs are more similar.\n",
    "Similarity Score = 1 - Cosine Distance\n",
    "The code then adds the similarity score to the result for each job, allowing us to see how similar each recommended job is to the input.\n",
    "5. **Returning the Results**:\n",
    "The top n most similar job postings are returned, displaying important details such as:\n",
    "Job ID\n",
    "Company Name\n",
    "Job Title\n",
    "Job Description\n",
    "Skills Description\n",
    "Location\n",
    "Similarity Score: A higher similarity score means the job posting is more relevant to the user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f844370-94f4-492f-af70-adf3194cca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import h5py\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e07d14-7307-4529-9b9c-461c1d27f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcedeefc-c569-4672-a6b8-894b20df062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess and lemmatize text\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters and lowercase the text\n",
    "    text = re.sub(r'\\W', ' ', text.lower())\n",
    "    # Tokenize and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "609b4f87-80f4-4139-8d2c-c614d5e79322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_recommend(title=None, skills=None, top_n=5):\n",
    "    model_directory = \"D:/ARJYAHI/Models\"\n",
    "    h5_file_path = os.path.join(model_directory, 'model_data.h5')\n",
    "    \n",
    "    with h5py.File(h5_file_path, 'r') as h5f:\n",
    "        # Load the TF-IDF vectorizer and NearestNeighbors model from HDF5\n",
    "        tfidf_vectorizer = pickle.loads(h5f['tfidf_vectorizer'][()].tobytes())\n",
    "        nbrs = pickle.loads(h5f['nbrs'][()].tobytes())\n",
    "    \n",
    "    # Combine title and skills into input text and preprocess\n",
    "    input_text = ' '.join(filter(None, [title, skills]))\n",
    "    input_text = preprocess_text(input_text)\n",
    "    \n",
    "    # Transform the input text using the loaded TF-IDF vectorizer\n",
    "    input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "    \n",
    "    # Find nearest neighbors (most similar jobs)\n",
    "    distances, indices = nbrs.kneighbors(input_tfidf, n_neighbors=top_n)\n",
    "    \n",
    "    # Load the job postings dataset\n",
    "    data = pd.read_csv(\"C:/Users/DELL/Linkedin-Job-Market-Analysis-using-ML/LinkedIn Scraper/job postings 2023 24/postings.csv\")\n",
    "    \n",
    "    # Return the top_n similar jobs\n",
    "    similar_jobs = data.iloc[indices[0]][[\"company_name\", \"title\", \"location\"]]\n",
    "    similar_jobs['similarity_score'] = 1 - distances[0]  # Cosine similarity score (higher is better)\n",
    "    \n",
    "    return similar_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42138f2-00de-466b-b158-cd1de75cfe88",
   "metadata": {},
   "source": [
    "## Example Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da2482fe-533c-4998-9e9c-dfc6025ea2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            company_name                                              title  \\\n",
      "69503             Nebula                                     Data Scientist   \n",
      "83764             Amazon  Language Data Scientist, Artificial General In...   \n",
      "83835             Amazon  Language Data Scientist, Artificial General In...   \n",
      "83406   Jobot Consulting                               Staff Data Scientist   \n",
      "116889          hackajob                                     Data Scientist   \n",
      "\n",
      "             location  similarity_score  \n",
      "69503   United States          0.500107  \n",
      "83764      Boston, MA          0.490506  \n",
      "83835      Boston, MA          0.490506  \n",
      "83406    New York, NY          0.477121  \n",
      "116889     McLean, VA          0.470805  \n"
     ]
    }
   ],
   "source": [
    "title_input = \"Data Scientist\"  # Or set it to None if only using skills\n",
    "skills_input = None  # Or set it to a skills string if only using skills\n",
    "similar_jobs = load_model_and_recommend(title=title_input, skills=skills_input)\n",
    "print(similar_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d03da4-0975-4d31-ab93-9a53ba7a9bbd",
   "metadata": {},
   "source": [
    "## Final Conclusion and Explanation of Similarity Scores and Cosine Metrics\n",
    "\n",
    "The final output provides a list of job postings that are most similar to the input text (either a job title, skills, or both). The key metric used to determine this similarity is the **cosine similarity score**. Here's a detailed explanation of the results and how the cosine similarity is calculated:\n",
    "\n",
    "### 1. **Similarity Scores:**\n",
    "   The **cosine similarity score** indicates how closely the input text (job title and/or skills) matches the job descriptions in the dataset. The score ranges from 0 to 1:\n",
    "   - **1** indicates perfect similarity, meaning the input is almost identical to the job description.\n",
    "   - **0** means no similarity at all.\n",
    "\n",
    "   The job postings in the result are sorted by their cosine similarity score, with higher scores indicating a higher degree of relevance to the input.\n",
    "\n",
    "   For example:\n",
    "   - **Data Scientist** at **Nebula** has a similarity score of **0.500107**, meaning it's the most similar job to the input.\n",
    "   - **Language Data Scientist, Artificial General Intelligence** at **Amazon** has a score of **0.490506**, indicating it's also highly relevant, but slightly less so than the Nebula job posting.\n",
    "   - **Staff Data Scientist** at **Jobot Consulting** has a similarity score of **0.477121**, showing it is somewhat less similar.\n",
    "   - **Data Scientist** at **hackajob** has the lowest similarity score of **0.470805**, but it's still relevant to the input.\n",
    "\n",
    "### 2. **Cosine Similarity:**\n",
    "   Cosine similarity is a metric used to measure how similar two vectors (in this case, job descriptions and the input text) are. It is calculated as the cosine of the angle between the vectors:\n",
    "   $$\n",
    "   \\text{Cosine Similarity} = \\frac{A \\cdot B}{|A| |B|}\n",
    "   $$\n",
    "   - **A** and **B** represent two vectors, such as one for the input text and one for the job description.\n",
    "   - The **dot product** (A â‹… B) measures how aligned the two vectors are.\n",
    "   - The **magnitude** |A| and |B| of the vectors normalizes the calculation, ensuring that the result is independent of the vector lengths.\n",
    "\n",
    "   A higher cosine similarity score means that the job description shares more common features with the input text, indicating that it is a better match.\n",
    "\n",
    "### 3. **Interpretation of Results:**\n",
    "   - The job postings with the highest similarity scores are more likely to match the user's input, based on the similarity between their job descriptions and the user's search query (title and/or skills).\n",
    "   - The cosine similarity metric is effective in capturing the semantic similarity between the input and the job descriptions, even if the exact words do not match. For example, similar job titles with slightly different wording can still receive a high similarity score.\n",
    "\n",
    "### 4. **Final Thoughts:**\n",
    "   - The similarity scores provide an intuitive way to rank job postings based on how well they match the input text.\n",
    "   - By using **cosine similarity**, we ensure that the recommendation system is sensitive to the context and meaning of the words, making it a robust method for job recommendation tasks.\n",
    "   - The top job recommendations are ranked by their similarity scores, helping the user quickly identify the most relevant job postings based on their interests or expertise.\n",
    "\n",
    "In conclusion, the cosine similarity metric serves as a powerful tool to find jobs that closely match the user's profile, providing a data-driven and efficient way to recommend similar job postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdafd6-9d67-4ab1-b806-f775f244f4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
