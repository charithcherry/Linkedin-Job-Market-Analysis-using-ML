{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2390c1-40f3-46c8-af46-dd133054b867",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This script is used to cluster job postings from a dataset (`df_A`) based on their titles and descriptions, matching them against predefined domains and sub-domains with associated keywords from another dataset (`df_B`). The code computes probabilities for each cluster based on keyword matches and assigns each job posting a primary and secondary cluster based on these probabilities.\n",
    "\n",
    "### Steps and Key Functions\n",
    "\n",
    "1. **Data Loading:**\n",
    "   - The job postings data is loaded from a CSV file (`postings.csv`) into a pandas DataFrame `df_A`.\n",
    "   - Domain and keyword mapping data is loaded from an Excel file (`Domain_TD.xlsx`) into another DataFrame `df_B`.\n",
    "\n",
    "2. **`find_clusters_with_probabilities` function:**\n",
    "   This function computes the probability that a job posting belongs to a specific domain and sub-domain cluster based on the following:\n",
    "   - It matches keywords in the job description and title with the keywords associated with domains and sub-domains in `df_B`.\n",
    "   - The probability is calculated based on the following rules:\n",
    "     - If there are matches in the title, 50% is assigned to that cluster.\n",
    "     - If there are 4 or more keyword matches in the description, 50% is assigned to that cluster.\n",
    "     - If there are fewer than 4 keyword matches in the description, a percentage of the 50% is assigned based on the number of matches.\n",
    "   \n",
    "3. **Cluster Assignment:**\n",
    "   - The function `find_clusters_with_probabilities` is applied to each job posting (row) in `df_A` to compute the clusters for each job posting. The result is stored in the new `clusters` column in `df_A`.\n",
    "   \n",
    "4. **Probability Calculation:**\n",
    "   - The script calculates the probability for each cluster, which is the proportion of the total matches for a specific cluster out of all the matches in the job posting.\n",
    "   - If a cluster has a match count greater than or equal to 100, it is assigned a probability of 100%.\n",
    "\n",
    "5. **Primary and Secondary Clusters:**\n",
    "   - After assigning clusters, the function `get_primary_secondary` sorts the clusters by their probabilities in descending order and assigns the primary and secondary clusters accordingly.\n",
    "   - The primary and secondary clusters are stored in new columns: `primary_cluster` and `secondary_cluster` in `df_A`.\n",
    "\n",
    "6. **Saving Results:**\n",
    "   - After processing, the updated DataFrame `df_A` is saved to a new CSV file (`df_A_clustered.csv`).\n",
    "\n",
    "### Example Output\n",
    "\n",
    "The output DataFrame will have the following columns:\n",
    "- `company_name`: The name of the company posting the job.\n",
    "- `title`: The job title.\n",
    "- `location`: The job location.\n",
    "- `clusters`: A dictionary containing domain:sub-domain pairs with their corresponding probabilities.\n",
    "- `primary_cluster`: The cluster with the highest probability.\n",
    "- `secondary_cluster`: The cluster with the second-highest probability.\n",
    "\n",
    "### Final Result\n",
    "\n",
    "The final DataFrame provides each job posting's primary and secondary cluster assignments, helping to categorize the job postings based on the relevance of the title and description to predefined domains and sub-domains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d68ec6-e008-453c-892f-1c18ffcb772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485b0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "df_A = pd.read_csv('../Job_Postings_Data_2023_24/postings.csv',encoding='latin-1')\n",
    "# df_A = df.sample(n=20000, random_state=42)\n",
    "df_B = pd.read_excel('Domain_TD.xlsx')\n",
    "\n",
    "# Initialize a new column in df_A for the cluster\n",
    "df_A['clusters'] = None\n",
    "df_A['title'] = df_A['title'].astype(str).fillna('')\n",
    "df_A['description'] = df_A['description'].astype(str).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f55f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters_with_probabilities(title, description, df_B):\n",
    "    cluster_matches = {}\n",
    "\n",
    "    for index, row in df_B.iterrows():\n",
    "        domain = row['Domain'].strip().lower()\n",
    "        sub_domain = row['Sub-Domain'].strip().lower()\n",
    "        #keywords = [keyword.strip().lower() for keyword in row['keywords'].split(',')]  # assuming keywords are comma-separated\n",
    "        keywords = [keyword.strip().lower() for keyword in row['keywords'].split(',')] if isinstance(row['keywords'], str) else []\n",
    "\n",
    "        # Match keywords in description\n",
    "        description_match_count = sum(1 for keyword in keywords if keyword in description.lower())\n",
    "        # Match keywords in title (checking each word in title against the keywords)\n",
    "        title_word_count = len([word for word in title.lower().split() if word in keywords])\n",
    "\n",
    "        cluster = f\"{row['Domain']}:{row['Sub-Domain']}\"\n",
    "\n",
    "        # If there are matches in the title (more than 0 words in title match keywords), assign 50%\n",
    "        if title_word_count > 0:\n",
    "            if cluster not in cluster_matches:\n",
    "                cluster_matches[cluster] = 0\n",
    "            cluster_matches[cluster] += 50  # Assign 50% for title matches\n",
    "\n",
    "        # If there are more than 4 keyword matches in the description, assign 50%\n",
    "        if description_match_count >= 4:\n",
    "            if cluster not in cluster_matches:\n",
    "                cluster_matches[cluster] = 0\n",
    "            cluster_matches[cluster] += 50  # Assign 50% for description matches\n",
    "\n",
    "        # If the description has less than 4 keyword matches, calculate percentage\n",
    "        if description_match_count < 4:\n",
    "            description_percentage = (description_match_count / 4) * 50\n",
    "            if cluster not in cluster_matches:\n",
    "                cluster_matches[cluster] = 0\n",
    "            cluster_matches[cluster] += description_percentage  # Add calculated percentage\n",
    "\n",
    "    if not cluster_matches:\n",
    "        return {'Uncategorized': 100}\n",
    "\n",
    "    # Calculate probabilities\n",
    "    total_matches = sum(cluster_matches.values())\n",
    "    probabilities = {}\n",
    "\n",
    "    for cluster, count in cluster_matches.items():\n",
    "        if count >= 100:\n",
    "            probabilities[cluster] = 100.0\n",
    "        else:\n",
    "            probabilities[cluster] = (count / total_matches) * 100.0\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a878d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row in df_A\n",
    "df_A['clusters'] = df_A.apply(lambda row: find_clusters_with_probabilities(row['title'], row['description'], df_B), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0451d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a new CSV file if needed\n",
    "df_A.to_csv('df_A_clustered.csv', index=False)6+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcea5104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'software engineer:general': 6.0,\n",
       " 'software engineer:aerospace': 0.0,\n",
       " 'software engineer:management': 4.0,\n",
       " 'software engineer:marketing': 0.0,\n",
       " 'software engineer:healthcare': 14.000000000000002,\n",
       " 'software engineer:cybersecurity': 0.0,\n",
       " 'software engineer:robotics': 2.0,\n",
       " 'software engineer:finance': 2.0,\n",
       " 'software engineer:automobile': 0.0,\n",
       " 'Robotics Engineer:Robotics': 2.0,\n",
       " 'software engineer:customer relationship management': 4.0,\n",
       " 'Accountant:finance': 4.0,\n",
       " 'nurse:healthcare': 100.0,\n",
       " 'Admin:management': 4.0,\n",
       " 'sales representative:sales': 8.0,\n",
       " 'sales manager:sales': 4.0,\n",
       " 'scrum master:management': 0.0,\n",
       " 'Architect:Design': 2.0,\n",
       " 'Assistant manager:management': 8.0,\n",
       " 'Business Analyst:general': 8.0,\n",
       " 'associate director:general': 2.0,\n",
       " 'automation engineer:general': 2.0,\n",
       " 'chief financial officer:finance': 4.0,\n",
       " 'transportation specialist:transport': 0.0,\n",
       " 'chef:food chain': 2.0,\n",
       " 'clerk:general': 2.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A.clusters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259c2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine primary and secondary clusters\n",
    "def get_primary_secondary(clusters):\n",
    "    sorted_clusters = sorted(clusters.items(), key=lambda item: item[1], reverse=True)\n",
    "    primary = sorted_clusters[0][0] if len(sorted_clusters) > 0 else None\n",
    "    secondary = sorted_clusters[1][0] if len(sorted_clusters) > 1 else None\n",
    "    return pd.Series([primary, secondary])\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "df_A[['primary_cluster', 'secondary_cluster']] = df_A['clusters'].apply(get_primary_secondary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4560b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123849"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9682417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.to_csv('df_A_clustered_PS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a679e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
